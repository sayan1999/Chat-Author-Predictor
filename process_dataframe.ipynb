{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your name mentioned in your whatsapp account at the time of exporting chats\n",
    "import json\n",
    "with open('./myname.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "my_name = data['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import movie_reviews\n",
    "from pandas import DataFrame, read_csv\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score \n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stopwords listing\n",
    "## Extend the list of stopwords by analyzing your language transiliterated in english (ex-hindi, bengali, telegu, tamil etc) for better precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Transliterated Hindi Words\n",
    "stopwords.extend(['hai','nhi','mai','toh','ho','kya','na','ka','hi','ki','tum','nahi','bhi',\n",
    "                  'haan','se','ke','tha','k','aur','rhe','ko','rhi','main','mujhe','abhi','voh','b',\n",
    "                  'hun','thi','hain','ek','kar','rha','e','hoga','kal','lekin','tumne',\n",
    "                  'hua','arey','pr','koi','liye','hum','maine','gaya','accha','aa','tumhe','mera',\n",
    "                  'kuch','yeh','hota','u','ye','time','bohot','er','tumhara','lab',\n",
    "                  'kyun','kr','class','fir','sir','hu','gayi','karna','chahiye','acha','n','jo','nt'])\n",
    "\n",
    "le = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):   \n",
    "    \n",
    "    tokens=word_tokenize(text.lower())\n",
    "    \n",
    "    punctuation=re.compile('[^a-zA-Z]*')    \n",
    "    post_punctutation=([punctuation.sub(\"\", word) for word in tokens])\n",
    "      \n",
    "    stem_token=[le.lemmatize(word) for word in post_punctutation if word not in stopwords]    \n",
    "    return \" \".join(stem_token) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Loading csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv('./dataset/whatsapp_df.csv')\n",
    "\n",
    "# preprocess the messages\n",
    "df['Message']=df['Message'].transform(lambda x : preprocess(x))\n",
    "\n",
    "# drop rows where message is too small\n",
    "message_threshold_size = 4\n",
    "df=df[df['Message'].apply(lambda x : len(word_tokenize(x)))>=message_threshold_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop your own messages as it may overshadow others' messages due to high occurence\n",
    "# comment it out if you want to include your chats\n",
    "df=df[df['Author'] != my_name]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sample(frac=1).reset_index(drop=True)\n",
    "df.to_csv('./dataset/processed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
