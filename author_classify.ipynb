{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.corpus import movie_reviews\n",
    "from pandas import DataFrame, read_csv\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score \n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=read_csv('./dataset/processed.csv')\n",
    "\n",
    "# if your dataset is large uncomment the following lines, \n",
    "# and tune the capacity_rows variable according to your ram capacity\n",
    "\n",
    "# import numpy as np\n",
    "# capacity_rows = 70000\n",
    "# if len(df) > capacity_rows:\n",
    "#     remove_n = len(df) - capacity_rows\n",
    "# drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "# df = df.drop(drop_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the words and label the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "vect=TfidfVectorizer()\n",
    "X=vect.fit_transform(df['Message'])\n",
    "dtm_df=DataFrame(X.toarray(), columns=vect.get_feature_names()) \n",
    "\n",
    "label=LabelEncoder()\n",
    "dtm_df['Author']=label.fit_transform(df['Author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release ram\n",
    "del(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size_fraction=0.2\n",
    "train_size = int(len(dtm_df)*(1-test_size_fraction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr=LogisticRegression(C=150)\n",
    "clf_lr.fit(dtm_df.loc[0:train_size][vect.get_feature_names()],dtm_df.loc[0:train_size]['Author'])\n",
    "pred=clf_lr.predict(dtm_df.loc[train_size:][vect.get_feature_names()])\n",
    "print(\"The accuracy of Logistic Regression :\" , accuracy_score(pred,dtm_df.loc[train_size:]['Author'])) \n",
    "print(\"The classification report is : \\n\"+classification_report(pred,dtm_df.loc[train_size:]['Author']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dump python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./objects/label.obj', 'wb') as label_file:\n",
    "    pickle.dump(label, label_file)\n",
    "with open('./objects/model.obj', 'wb') as model_file:\n",
    "    pickle.dump(clf_lr, model_file)\n",
    "with open('./objects/vect.obj', 'wb') as vect_file:\n",
    "    pickle.dump(vect, vect_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
